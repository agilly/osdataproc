---

- name: Start Spark slave
  service: name=spark-slave state=started enabled=yes
 
- name: Wait for datanodes to register
  shell: "{{ hadoop_home }}/bin/hdfs dfsadmin -report | grep -A1 Name"
  retries: 50
  delay: 10
  register: result
  until: result.rc == 0

- name: Write slave IPs and hostnames to /etc/hosts
  become: yes
  shell: "{{ hadoop_home }}/bin/hdfs dfsadmin -report | grep -A1 Name | awk -F' ' '{print $2}' | cut -d\":\" -f1 | tr '\n' ' ' >> /etc/hosts"

- name: Split IPs and hostnames on to newlines
  become: yes
  replace:
          path: /etc/hosts
          regexp: '192'
          replace: '\n192'
          backup: yes
