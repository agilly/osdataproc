---

- name: Start Spark slave
  service: name=spark-slave state=started enabled=yes
 
- name: Wait for datanodes to register
  shell: "{{ hadoop_home }}/bin/hdfs dfsadmin -report | grep -A1 Name"
  retries: 50
  delay: 10
  register: result
  until: result.rc == 0

- name: Wait 1 minute for all datanodes
  pause:
          minutes: 1

- name: Write slave IPs and hostnames to /etc/hosts
  become: yes
  shell: "{{ hadoop_home }}/bin/hdfs dfsadmin -report | grep -A1 Name | awk -F' ' '{print $2}' | cut -d\":\" -f1 | tr '\n' ' ' >> /etc/hosts"

- name: Split IPs and hostnames on to newlines
  become: yes
  replace:
          path: /etc/hosts
          regexp: '(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'
          replace: '\n\1'
          backup: yes

- name: Install Netdata
  shell: "cd {{ netdata_dir }} && ./netdata-installer.sh --dont-wait"
